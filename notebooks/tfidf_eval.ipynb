{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af97a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.preprocess.tf_idf_vectors import load_vectorizer as load_tfidf\n",
    "from src.preprocess.tf_idf_vectors import read_jsonl\n",
    "from src.preprocess.fasttext_vectors import load_fasttext_vectors, tokenize\n",
    "from src.config.paths import (\n",
    "    poleval2022_questions_path,\n",
    "    poleval2022_subdataset_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = load_tfidf(\"wiki-trivia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadfb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_cosine_sparse_rows(q_vec, X, topk=5, chunk_size=50_000, assume_l2_normalized=True, eps=1e-12):\n",
    "    \"\"\"\n",
    "    q_vec: (1, D) sparse\n",
    "    X:     (N, D) sparse\n",
    "    Returns: list[(score, row_index)] sorted desc\n",
    "    \"\"\"\n",
    "    heap = []\n",
    "\n",
    "    # only needed if not normalized\n",
    "    if not assume_l2_normalized:\n",
    "        q_norm = np.sqrt(q_vec.multiply(q_vec).sum()) + eps\n",
    "\n",
    "    N = X.shape[0]\n",
    "    for start in range(0, N, chunk_size):\n",
    "        end = min(start + chunk_size, N)\n",
    "        Xb = X[start:end]\n",
    "\n",
    "        dots = Xb @ q_vec.T\n",
    "        sims = dots.toarray().flatten()\n",
    "\n",
    "        if not assume_l2_normalized:\n",
    "            Xb_norm = np.sqrt(Xb.multiply(Xb).sum(axis=1)).A1 + eps\n",
    "            sims = sims / (Xb_norm * q_norm)\n",
    "\n",
    "        k_local = min(topk, sims.size)\n",
    "        if k_local == 0:\n",
    "            continue\n",
    "\n",
    "        idx_local = np.argpartition(-sims, k_local - 1)[:k_local]\n",
    "        for i in idx_local:\n",
    "            item = (float(sims[i]), start + int(i))\n",
    "            if len(heap) < topk:\n",
    "                heapq.heappush(heap, item)\n",
    "            else:\n",
    "                heapq.heappushpop(heap, item)\n",
    "\n",
    "    heap.sort(reverse=True)\n",
    "    return heap\n",
    "\n",
    "\n",
    "def retrieve_topk_tfidf(question_text, vectorizer, passages_matrix, k=5, chunk_size=50_000):\n",
    "    q_vec = vectorizer.transform([question_text])\n",
    "    assume_norm = (getattr(vectorizer, \"norm\", None) == \"l2\")  # default True for TfidfVectorizer\n",
    "\n",
    "    top = topk_cosine_sparse_rows(\n",
    "        q_vec=q_vec,\n",
    "        X=passages_matrix,\n",
    "        topk=k,\n",
    "        chunk_size=chunk_size,\n",
    "        assume_l2_normalized=assume_norm,\n",
    "    )\n",
    "\n",
    "    scores = [s for s, _ in top]\n",
    "    idx = [i for _, i in top]\n",
    "\n",
    "    results = pd.Series(scores, index=idx)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6db368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"piotr-rybak__poleval2022-passage-retrieval-dataset\"\n",
    "subdataset = \"wiki-trivia\"\n",
    "split = \"train\"  # \"train\" or \"test\"\n",
    "\n",
    "subdataset_dir = poleval2022_subdataset_dir(dataset_id, subdataset)\n",
    "questions_path = poleval2022_questions_path(dataset_id, subdataset, split)\n",
    "questions_df = read_jsonl(questions_path).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276dd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "qid = 12\n",
    "question_text = questions_df.loc[qid, \"text\"]\n",
    "scores_by_row = retrieve_topk_tfidf(\n",
    "    question_text=question_text,\n",
    "    vectorizer=tf[\"vectorizer\"],\n",
    "    passages_matrix=tf[\"matrix\"],\n",
    "    k=k,\n",
    "    chunk_size=50_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f784892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_passage_ids = tf[\"passage_ids\"][scores_by_row.index.to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45078878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5406-19       0.412167\n",
       "2224431-0     0.406479\n",
       "445532-3      0.390036\n",
       "1352589-29    0.335980\n",
       "3265537-6     0.334461\n",
       "3031599-30    0.331957\n",
       "4468-0        0.322450\n",
       "3873232-7     0.312494\n",
       "5045784-0     0.311857\n",
       "3031599-29    0.307448\n",
       "dtype: float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(scores_by_row.to_numpy(dtype=np.float32), index=top_passage_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF test retrieval chunks: 6639839/6639839\n",
      "Wrote: /home/mateusz/dev/inl_pjatk_project/.cache/submissions/tfidf_wiki-trivia_questions-test.tsv\n",
      "Hits@10: 0.3757 (485/1291)\n",
      "MRR@10:  0.1866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mateusz/dev/inl_pjatk_project/.cache/submissions/tfidf_wiki-trivia_questions-test.tsv')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorized TF-IDF retrieval + evaluation helper (reusable for FAISS later)\n",
    "from src.eval.retrieval_eval import evaluate_and_write_submission, retrieve_tfidf_topk\n",
    "\n",
    "dataset_id = \"piotr-rybak__poleval2022-passage-retrieval-dataset\"\n",
    "subdataset = \"wiki-trivia\"\n",
    "split = \"test\"\n",
    "k = 10\n",
    "\n",
    "result = evaluate_and_write_submission(\n",
    "    dataset_id=dataset_id,\n",
    "    subdataset=subdataset,\n",
    "    questions_split=split,\n",
    "    pairs_split=split,  # set None if you want \"submission only\"\n",
    "    k=k,\n",
    "    retriever=lambda texts, k: retrieve_tfidf_topk(\n",
    "        vectorizer=tf[\"vectorizer\"],\n",
    "        passages_matrix=tf[\"matrix\"],\n",
    "        passage_ids=tf[\"passage_ids\"],\n",
    "        query_texts=texts,\n",
    "        k=k,\n",
    "        chunk_size=10_000,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Wrote:\", result.out_path)\n",
    "if result.hits_at_k is not None:\n",
    "    print(f\"Hits@{k}: {result.hits_at_k:.4f}\")\n",
    "    print(f\"MRR@{k}:  {result.mrr_at_k:.4f}\")\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inl-pjatk-project (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
